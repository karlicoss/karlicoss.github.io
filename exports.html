<!doctype html>
<html lang="en" prefix="og: http://ogp.me/ns#">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <!-- Icon made by Twitter -->
        <!-- https://twemoji.twitter.com/content/twemoji-twitter/en.html -->
        <link rel="icon" href="./robot-face.png">
        <link rel="apple-touch-icon" href="./robot-face.png">

        <meta name="generator" content="hakyll">
        <meta name="language" content="English">
        
        <meta name="keywords" content="infra dataliberation pkm">
        
        <!-- TODO concat with keywords tags; also need to make comma separated? -->

        <title>Building data liberation infrastructure | Mildly entertainingᵝ</title>

        <link href="https://fonts.googleapis.com/css?family=Source+Serif+Pro" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="./css/default.css?v=3" />
        <!-- TODO make conditional?? -->
        <link rel="stylesheet" href="./css/posts-list.css" /> 
        <link rel="stylesheet" href="./css/links.css?v=4" />

        

        <link rel="canonical" href="https://beepb00p.xyz/exports.html" />

        <!-- can test it with https://telegram.me/webpagebot -->
        <!-- or https://developers.facebook.com/tools/debug -->
        <meta property="og:type" content="website" />
        <meta property="og:url" content="https://beepb00p.xyz/exports.html" /> <!-- TODO base? -->
        <meta property="og:title" content="Building data liberation infrastructure | beepb00p" />
        <meta property="og:description" content="How to export, access and own your personal data with minimal effort" />
        <!-- ugh. why is image necessary??? otherwise other parts aren't working or I get lots of 404s -->
        <!-- ugh. Facebook really wants jpg? -->
        <!-- also Facebook displays it with black background, but whatever, fuck it. -->
        <meta property="og:image" content="https://beepb00p.xyz/robot-face.jpg" />

    </head>
    <body>
        <!-- TODO make semantic -->
        <header>
            <nav>
                <span class="nav-left">
                    <a class="fat" href="./">Home</a>
                    <!-- TODO eh, not sure if this symbol is good for that... -->
                    ·
                    <a class="fat" href="./ideas.html">Ideas</a>
                    ·
                    <a class="fat" href="./notes.html">Notes</a>
                    ·
                    <a class="fat" href="./tags.html">Tags</a>
                </span>
                <span class="nav-right">
                    <a class="fat" href="./feed.html">Feed</a>
                    ·
                    <a class="fat" href="./site.html">Site</a>
                    ·
                    <a class="fat" href="./me.html">Me</a>
                </span>
            </nav>
        </header>

        <main>
            

<!-- <link rel="stylesheet" href="/css/org.css" /> -->

<link rel="stylesheet" href="./css/htmlize.css" />
<link rel="stylesheet" href="./css/org-default.css" />

<link rel="stylesheet" href="./css/org-extra.css?v=3" />



<article>
    
    <div>THIS IS A DRAFT! It will appear on the main page once finished!</div>
    
    <section class="post-title">
    <h1>Building data liberation infrastructure</h1>
    <div class="summary">How to export, access and own your personal data with minimal effort</h2>
    </section>
    <!-- are sections appropriate for that? -->

    <section class="content">
    <p>
<b>Draft stage</b>: mostly ready in terms of what I want to say and structure, writing needs to be improved.
</p>
<p>
Our personal data is siloed, held hostage, and very hard to access for various tecnhical and business reasons.
I wrote and vented a lot about in the <a href="sad-infra.html">previous post</a>.
</p>
<p>
People suggest a whole spectrum of possible solutions to these issues, starting from proposals on dismantling capitalism and ending with high tech vaporwavy stuff like <a href="https://en.wikipedia.org/wiki/Urbit">urbit</a>.
</p>
<p>
I, however, want my data <b>here and now</b>. I'm also fortunate to be a software engineer so I can bring this closer to reality by myself.
</p>
<p>
As a pragmatic intermediate solution, feasible with existing technology and infrastructure without reinventing everything from scratch, 
I suggested a <a href="sad-infra.html#data_mirror">'data mirror'</a>, an app that continuously syncs/mirrors user's personal data.
</p>
<p>
So, as I promised, this post will be somewhat more specific (some might say boring).
I will be presenting and elaborating on different technical decisions, patterns and tricks I figured out while developing data mirrors by myself.
In hindsight some things feel so obvious that they hardly deserve mention, but I hope that would be helpful anyway!
</p>
<p>
You can also read this as a kind of <b>tutorial</b> on liberating your data from any service.
</p>
<p>
I'm also <b>extremely open</b> to hear questions like "Why didn't you do Y instead of X?". 
It's quite possible that I'm slipping extra complexity somewhere and I would be very happy to eliminate it.
</p>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#design">1. Design principles</a></li>
<li><a href="#retrieve">2. Retrieving data</a>
<ul>
<li><a href="#org0000000">public API</a></li>
<li><a href="#org0000001">private API</a></li>
<li><a href="#export_scrape">scraping</a></li>
<li><a href="#export_manual">manual export (GDPR/takeout)</a></li>
<li><a href="#export_phone">phone apps</a></li>
<li><a href="#export_devices"><span class="todo TODO">TODO</span> devices?</a></li>
</ul>
</li>
<li><a href="#types">3. Types of exports</a>
<ul>
<li><a href="#full">full export</a></li>
<li><a href="#incremental">incremental export</a></li>
<li><a href="#synthetic">synthetic export</a></li>
</ul>
</li>
<li><a href="#export_layer">4. Export layer</a>
<ul>
<li><a href="#bindings">use existing bindings</a></li>
<li><a href="#org0000002">do not mess with raw data</a></li>
<li><a href="#org0000003">do not be too defensive</a></li>
<li><a href="#output_stdout">output to stdout</a></li>
<li><a href="#org0000004"><span class="timestamp-wrapper"><span class="timestamp">[2019-12-26 23:22]</span></span> allow reading credentials from a file</a></li>
</ul>
</li>
<li><a href="#org0000005">5. How to store it: organizing data</a>
<ul>
<li><a href="#timestamps">naming and timestamping</a></li>
<li><a href="#backups">backups</a></li>
<li><a href="#sync">synchronizing between computers</a></li>
<li><a href="#disk_space">disk space concerns</a></li>
</ul>
</li>
<li><a href="#arctee">6. arctee</a>
<ul>
<li><a href="#org0000006"><span class="todo TODO">TODO</span> <span class="timestamp-wrapper"><span class="timestamp">[2019-12-28 23:56]</span></span> I guess in 'DAL' mention that bwrapper is useful here too.</a></li>
<li><a href="#org0000007"><span class="todo TODO">TODO</span> <span class="timestamp-wrapper"><span class="timestamp">[2020-01-19 18:34]</span></span> dunno, perhaps move to 'appendix'?? along with cachew?</a></li>
</ul>
</li>
<li><a href="#automatic_exports">7. Automating exports</a></li>
<li><a href="#dal">8. Data access layer (DAL)</a>
<ul>
<li><a href="#org0000008">you need to cache data on the disk anywa</a></li>
<li><a href="#org0000009"><span class="todo TODO">TODO</span> <span class="priority">[C]</span> would be nice to have main for models?   <span class="tag"><span class="dataliberation">dataliberation</span></span></a></li>
<li><a href="#org000000a"><span class="todo TODO">TODO</span> it's also an experiment in organizing code. demo etc, immediately visualize stuff with pandas   <span class="tag"><span class="exports">exports</span> <span class="blog">blog</span> <span class="dal">dal</span></span></a></li>
</ul>
</li>
<li><a href="#org000000b">9. --</a></li>
<li><a href="#org000000c">10. <span class="todo TODO">TODO</span> add rationale behind the dal/export separation   <span class="tag"><span class="exports">exports</span></span></a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org000000d">
<h2 id="design"><a class="headerlink" href="#design">¶</a><span class="section-number-2">1</span> Design principles</h2>
<div class="outline-text-2" id="text-design">
<p>
So just as reminder, what is the goal of data mirror?
Having personal data <b>continuously/periodically synchronized</b> to the file system; and having <b>programmatic access</b> to it.
</p>
<p>
That may be not that hard to achieve for one particular data source, but when you want to use ten or more (TODO link to what I export),
each having its own quirks it becomes quite painful to write and support.
So there is TODO are? lots of incentive to make is, simple, generic, reliable and flexible at the same time, which isn't an easy goal.
</p>
<div><span class="before-aside">
Cornerstone of my design is modularity and separation of concerns. Most of my pipelines for data liberation consist of the following layers:

</span><aside class="sidenote">please don't be terrified of the word 'layer', typically these are just single scripts</aside></div>
<ul class="org-ul">
<li><p>
<a class="link-down" href="#export_layer">export layer</a>: knows how to get your data
</p>
<p>
The purpose of export layer is to reliably fetch and serialize raw data on your disk.
</p>
<p>
Export script deals with tedious business of authorization, pagination, being tolerant to network errors, etc.
</p>
<p>
Example: export layer for my <a href="https://github.com/karlicoss/endoexport/blob/e322b44ca1e6e5a779b4e7ea49564ba60d425bfe/export.py#L10-L15">Endomondo data</a> 
is fetching workouts data from the API (using existing library bindings) and prints the json out. That's all it does.
</p>
<p>
In theory, this layer is the only essential one; merely having raw json data on the filesystem enables you to use numerous tools to explore and analyze your data. However, long term you'll find yourself doing same manipulations all over again, and that's why we also need:
</p></li>
<li><p>
<a class="link-down" href="#dal">data access layer (DAL)</a>: knows how to read your data
</p>
<p>
For brevity, I'll refer to it as <b>DAL</b> (Data Abstraction/Access Layer).
</p>
<p>
Purpose of DAL is simply deserializing whatever export script dumped and providing minimalistic data bindings.
It shouldn't worry about tokens, network errors, etc., once you have your data on the disk DAL should be able to handle it even when you're offline.
</p>
<p>
It's not meant to be too high level though TODO mypkg
</p>
<p>
Example: <a href="https://github.com/karlicoss/fbmessengerexport/blob/a8f65a259dfa36ab6d175461994356947ded142a/model.py#L27-L47">DAL for Facebook Messenger</a> knows how to read messages from the database, access certain fields (e.g. message body) and handle obscure details like converting timestamps to <samp class="inline">datetime</samp> object. It's <b>not</b> trying to get messages from Facebook, which makes it way faster and more reliable to interact with data.
</p></li>
</ul>
<p>
It's clearly reasonable to keep export code and DAL code close as you don't want them to go out of sync and that's what I'm doing (TODO).
</p>
<p>
There is also what you could call the third layer which consists of downstream consumers of abstract (i.e. non-raw) data from DAL.
These are the actually interesting bits of TODO that contain visualizations, interactions across different data sources etc. 
I mention some of them <a href="sad-infra.html#mypkg">here</a>.
</p>
<p>
Now I'm going to elaborate on implementing export layer.
</p>
</div>
</div>
<div class="outline-2" id="outline-container-org0000012">
<h2 id="retrieve"><a class="headerlink" href="#retrieve">¶</a><span class="section-number-2">2</span> Retrieving data</h2>
<div class="outline-text-2" id="text-retrieve">
<p>
First step in exporting and liberating your data is to figure out how are you actually supposed to fetch it?
</p>
<p>
This addresses the authorization problem. TODO?
TODO maybe just mention the problems we're solving in the intro?
</p>
<p>
TODO Ordered from best to worst.
</p>
<p>
I'll mostly refer to Python libraries since that's what I'm familiar with, but I'm quite sure there are analogues in other languages.
</p>
<p>
Also remember, this is just to fetch data! You can serialize your export as any common format, and use any other programming language you like to access it.
That's the beauty of decoupling.
</p>
</div>
<div class="outline-3" id="outline-container-org0000000">
<h3 id="org0000000"><a class="headerlink" href="#org0000000">¶</a>public API</h3>
<div class="outline-text-3" id="text-org0000000">
<p>
You register your app, authorize it, get a token, and you are free to call various endpoints and fetch whatever you want.   
</p>
<p>
I won't really elaborate on it TODO, if you're reading this you probably have some idea how to use it.
Otherwise, I'm sure there are tutorials out there that would help you.
</p>
<p>
<span style="color:darkorange"><strong>if anyone knows decent ones, please let me know, I'll add links!</strong></span>
</p>
<p>
Examples: thankfully, most services out there offer public API to some extent
</p>
</div>
</div>
<div class="outline-3" id="outline-container-org0000001">
<h3 id="org0000001"><a class="headerlink" href="#org0000001">¶</a>private API</h3>
<div class="outline-text-3" id="text-org0000001">
<p>
Sometimes service doesn't offer an API. 
But from the developer's perspective, it's still very reasonable to use one when you've got backend/frontend communication.
</p>
<p>
So chances are, the service just isn't exposing it, but you can spy on the token/cookies in your browser devtools and use them to access the API.
</p>
<p>
You can read more about handling such data sources here:
</p>
<ul class="org-ul">
<li><a href="https://willschenk.com/articles/2019/reverse_engineering_apis_using_chrome">Reverse engineering APIs using Chrome Developer Tools</a>: an extremely comprehensive and beginner-friendly tutorial</li>
<li><a href="https://www.freecodecamp.org/news/how-i-used-python-to-find-interesting-people-on-medium-be9261b924b0">"How I used Python to find interesting people to follow on Medium"</a>, example of reverse engineering Medium API and using devtools</li>
<li><a href="https://blog.tendigi.com/starbucks-should-really-make-their-apis-public-6b64a1c2e923">Starbucks should really make their API public</a>: demo of reverse engineering Starbucks Android app, featuring using proxy and ??? fingerprint</li>
</ul>
<p>
Some examples:
</p>
<ul class="org-ul">
<li>for <a href="https://github.com/karlicoss/fbmessengerexport">exporting Messenger data</a>, I'm using <a href="https://fbchat.readthedocs.io/en/stable">fbchat</a> library. It works by tricking Facebook into believing it's a browser and interacting with private API.</li>
<li>even though Pocket has API, to get highlights from it, you need to <a href="https://github.com/karlicoss/pockexport#setting-up">spy on API key</a> they use in browser</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org000000e">
<h3 id="export_scrape"><a class="headerlink" href="#export_scrape">¶</a>scraping</h3>
<div class="outline-text-3" id="text-export_scrape">
<p>
Sometimes service doesn't offer an API, doesn't use it even internally and serves HTML pages directly instead.
Or, reverse engineering API is so painful that scraping becomes a more feasible option.
</p>
<p>
Apart from TODO link? difficulties, there are extras here:
</p>
<ul class="org-ul">
<li>authorization is harder: you definitely need username/password and potentially even 2FA token</li>
<li>DDOS protection: captchas, Cloudflare, etc.</li>
<li>or even deliberate anti-scraping measures</li>
</ul>
<p>
For Python the holy grail of scraping is <a href="https://scrapy.org">scrapy</a>:
</p>
<ul class="org-ul">
<li><a href="http://sangaline.com/post/advanced-web-scraping-tutorial">Advanced Web Scraping Tutorial</a>: bypassing "403 Forbidden", captchas, and more</li>
<li><a href="https://gist.github.com/alecxe/fc1527d6d9492b59c610">self-contained minimum example script to run scrapy</a></li>
</ul>
<p>
I'm pretty sure there are similar libraries for other languages, perhaps you could start with <a href="https://github.com/lorien/awesome-web-scraping">awesome-web-scraping repo</a> or <a href="https://news.ycombinator.com/item?id=15694118">Ask HN: What are best tools for web scraping?</a>.
</p>
<p>
For dealing with authorization, my personal experience is that using persistent <a href="https://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.firefox.firefox_profile">profile directory</a> in Selenium is sufficient in most cases: you can login once manually and after that, reuse the profile in your scripts.
</p>
<p>
Examples:
</p>
<ul class="org-ul">
<li>even though Hackernews has <a href="https://github.com/HackerNews/API">API for public data</a>, there is no way of getting your upvotes/saves without scraping HTML.</li>
<li>Amazon or Paypal have to be <a href="https://github.com/jbms/finance-dl#supported-data-sources">scraped</a> if you want your data.</li>
<li>my bank, HSBC doesn't have an API. Not that I expected it from HSBC, I don't live in a fairy tail; but even their manual transactions exports are in PDF which I have to <a href="https://github.com/karlicoss/hsbc-parser">parse</a>.</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org000000f">
<h3 id="export_manual"><a class="headerlink" href="#export_manual">¶</a>manual export (GDPR/takeout)</h3>
<div class="outline-text-3" id="text-export_manual">
<p>
It's great they exist, and it is the easiest way to get your data if you just want a backup.
That doesn't really help in the log run though:
</p>
<ul class="org-ul">
<li>you can only do it now and then</li>
<li>it's manual: typically requires requesting and clicking on email link.</li>
</ul>
<ul class="org-ul">
<li>it's slow and asynchronous: normally takes few days</li>
<li>format differs from API format, often ends up as something neither machine friendly nor human friendly</li>
</ul>
<p>
That said, with certain effort it can potentially be automated too.
</p>
<p>
They can be useful to get 'initial' bit of your data, past the <a href="sad-infra.html#data_is_vanishing">API limits</a>.
</p>
<p>
Examples:
</p>
<ul class="org-ul">
<li><a href="https://takeout.google.com">Google Takeout</a></li>
<li><a href="https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive">Twitter Archive</a></li>
<li><a href="https://github.blog/2018-12-19-download-your-data">Github</a> data export</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org0000010">
<h3 id="export_phone"><a class="headerlink" href="#export_phone">¶</a>phone apps</h3>
<div class="outline-text-3" id="text-export_phone">
<p>
I don't have iPhone, so will only be referring to Android in this section, but I'd imagine the situation is similar.
</p>
<p>
These days, service might not even offer desktop version at all, and considering that scraping data off mobile apps is way harder, getting it from the phone directly might be an easier option. In addition, the data is often kept as an sqlite database, which is in many ways even better than using API!
</p>
<p>
On Android the story is simple: apps keep their data in <samp class="inline">/data/data/</samp> directory, which is not accessible unless you <b>root</b> your phone.
These days, with <a href="https://magiskmanager.com">magisk</a> it's considerably easier, however it's still definitely not something a typical Android user would be able to do. Also rooting your phone can bring all sorts of trouble by triggering root detection (e.g. common in banking apps), so be careful.
</p>
<p>
Once you have root, you can write a script to copy necessary files from <samp class="inline">/data/data/</samp> to your target directory, synchronized with your computer (e.g. via <a href="https://play.google.com/store/apps/details?id=com.ttxapps.dropsync&amp;hl=en_GB">dropbox</a> or <a href="https://play.google.com/store/apps/details?id=com.github.catfriend1.syncthingandroid&amp;hl=en_GB">syncthing</a>).
</p>
<p>
I'm using <a href="https://play.google.com/store/apps/details?id=com.llamalab.automate&amp;hl=en">Automate app</a> to run export scripts on the phone, but that feels like something that should be solved by a cron-like tool, so please let me know if you know one!
</p>
<p>
Examples:
</p>
<ul class="org-ul">
<li>you can export Whatsapp data by copying <samp class="inline">/data/data/com.whatsapp/databases/msgstore.db</samp></li>
<li><a href="https://github.com/karlicoss/promnesia/blob/master/scripts/backup-phone-history.sh">scripts</a> for exporting mobile Chrome/Firefox browsing history</li>
<li>exporting <a href="https://bluemaestro.com">Bluemaestro</a> environment sensor data</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org0000011">
<h3 id="export_devices"><a class="headerlink" href="#export_devices">¶</a><span class="todo TODO">TODO</span> devices?</h3>
<div class="outline-text-3" id="text-export_devices">
<p>
TODO better name?
</p>
<p>
Finally, the nastiest TODO???
</p>
<p>
Here I'm referring to standalone specific-purpose devices like sleep trackers, e-ink readers, etc, TODO ?? when device doesn't have Interenet access or doesn't talk to any API.
</p>
<p>
You've got several options here:
</p>
<ul class="org-ul">
<li><p>
device is capable of synchronizing with your phone (e.g. via Bluetooth)
</p>
<p>
It's probably easiest to rely on <a class="link-up" href="#export_phone">phone app exports</a> here.
If sync has to be triggered manually, you can benefit from some <a href="https://play.google.com/store/apps/details?id=com.llamalab.automate&amp;hl=en">UI automation</a>.
</p></li>
<li><p>
device is running Linux and has Internet access
</p>
<p>
That's often the case with e-ink readers.
</p>
<p>
You can potentially run export script on the device itself and send the data somewhere else.
Another option is running SSH server on the device and pulling data from it, but it's quite extreme.
</p></li>
<li><p>
device can mount to a computer
</p>
<p>
Then, you can use <a href="https://en.wikipedia.org/wiki/Udev">udev</a> to trigger export when device is plugged in.
If udev feels too complicated to you, even a cron script running every minute might be enough.
</p></li>
</ul>
<p>
Examples:
</p>
<ul class="org-ul">
<li>using <a href="https://github.com/karlicoss/kobuddy#as-a-backup-tool">kobuddy</a> for semiautomatic exports from Kobo e-ink reader</li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org000001d">
<h2 id="types"><a class="headerlink" href="#types">¶</a><span class="section-number-2">3</span> Types of exports</h2>
<div class="outline-text-2" id="text-types">
<p>
Hopefully the previous section answers your questions on 'where do I get my data from'.
</p>
<p>
Now, let's establish a bit of vocabulary here.
Since data exports by their nature are somewhat similar to <a href="https://en.wikipedia.org/wiki/Backup#Backup_methods">backups</a>, I'm borrowing some terminology.
</p>
<p>
The way I see it, there are three styles of data exports:
</p>
</div>
<div class="outline-3" id="outline-container-org0000015">
<h3 id="full"><a class="headerlink" href="#full">¶</a>full export</h3>
<div class="outline-text-3" id="text-full">
<p>
Every time you want your data, go exhaustively through all the endpoints, and fetch the data.
As a result you get some sort of JSON file, which you can save on the disk.
</p>
<p>
Typically, with full exports, it's okay to overwrite the older export once you fetched everything. 
However I wouldn't recommend it (TODO backups and also atomic stuff?)
</p>
</div>
<div class="outline-4" id="outline-container-org0000013">
<h4 id="org0000013">summary</h4>
<div class="outline-text-4" id="text-org0000013">
<ul class="org-ul">
<li>advantages
<ul class="org-ul">
<li>very straightforward to implement</li>
</ul></li>
<li>disadvantages
<ul class="org-ul">
<li><b>might be impossible</b> due to <a href="sad-infra.html#data_is_vanishing">API restrictions</a></li>
<li>takes <b>more resources</b>, i.e. time/bandwith/cpu/memory</li>
<li>takes <b>more space</b> if you're keeping old versions</li>
<li>might be <b>flaky</b> due to excessive network requests</li>
</ul></li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-org0000014">
<h4 id="org0000014">examples</h4>
<div class="outline-text-4" id="text-org0000014">
<p>
When would you use that kind of export?
When there isn't much data to retrieve and you can do it in one go.
</p>
<ul class="org-ul">
<li><p>
<a href="https://github.com/karlicoss/pockexport">Exporting Pocket data</a>
</p>
<p>
There are no apparent API limitations preventing from fetching everything, and it seems like a plausible option, presumably it's a matter of transferring few hundred kilobytes. YMMV, if you are using it extremely heavily, you might want to use <a class="link-down" href="#synthetic">synthetic export</a> export.
</p></li>
</ul>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org0000018">
<h3 id="incremental"><a class="headerlink" href="#incremental">¶</a>incremental export</h3>
<div class="outline-text-3" id="text-incremental">
<p>
'Incremental' means that rerunning export starts off latest persisted state and only fetches missing data.
</p>
<p>
Implementation wise, it looks like this:
</p>
<ul class="org-ul">
<li>query previously exported data to determine the point (e.g. timestamp/message id) to continue from</li>
<li>fetch missing data starting from that point</li>
<li>merge it back with previously exported data, persist on disk</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org0000016">
<h4 id="org0000016">summary</h4>
<div class="outline-text-4" id="text-org0000016">
<ul class="org-ul">
<li>advantages
<ul class="org-ul">
<li>takes less resources</li>
<li>more resilient (if done right) as needs less network operations</li>
</ul></li>
<li>disadvantages
<ul class="org-ul">
<li>potentially very error prone, harder to implement
<ul class="org-ul">
<li>if you're not careful with <a href="sad-infra.html#pagination">pagniation</a> and misinterpret documentation you might never request some data</li>
<li>if you're not careful with <a href="sad-infra.html#consistency">transactional logic</a>, you might leave your export in an inconsistent state</li>
</ul></li>
</ul></li>
</ul>
<div><span class="before-aside">
Incremental exports are <b>always</b> harder to program. Indeed, <a class="link-up" href="#full">full export</a> is just an edge case of incremental one.

</span><aside class="sidenote">Fun fact: most of your phone apps already implement incremental sync. It's a shame the logic can't be reused.</aside></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0000017">
<h4 id="org0000017">examples</h4>
<div class="outline-text-4" id="text-org0000017">
<p>
So why would you bother with exporting data incrementally?
</p>
<ul class="org-ul">
<li><p>
too much data
</p>
<p>
This doesn't even mean too much in terms of bandwidth/storage, more of 'too many entities'.
</p>
<p>
E.g. imagine you want to export your Twitter timeline of 10000 tweets, that's about 1Mb of raw text data.
Even if you account for extra garbage and assume 10 Mb or even 100 Mb of data, it's basically nothing if you're running it once a day.
</p>
<p>
However, APIs usually impose pagination (e.g. 200 tweets per call), so to get these 10000 tweets you might have to do <code class="inline">10000 / 200 = 50</code> API calls. 
Suddenly the whole thing feels much less reliable, so you might want to make it incremental in order to minimize number of network calls.
</p>
<p>
For example:
</p>
<ul class="org-ul">
<li><a href="https://github.com/fabianonline/telegram_backup">Telegram</a>/<a href="https://github.com/karlicoss/fbmessengerexport">Messenger</a>/Whatsapp – basically IM always means there's too much data to be exported at once</li>
</ul></li>
<li><p>
flaky/slow API
</p>
<p>
If it's the case you want to minimize network interaction.
</p>
<p>
For example:
</p>
<ul class="org-ul">
<li><a class="link-up" href="#export_scrape">web scraping</a> is always somewhat slow; in addition you might have to rate limit yourself so you don't get banned by DDOS prevention.
Also it's is even flakier than using APIs, so you might want to avoid extra work if possible.</li>
<li><a href="https://shop-eu.emfit.com/products/emfit-qs">Emfit QS</a> sleep data: API is a bit flaky, so I minimize network interaction by caching previous data on disk</li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org000001c">
<h3 id="synthetic"><a class="headerlink" href="#synthetic">¶</a>synthetic export</h3>
<div class="outline-text-3" id="text-synthetic">
<div><span class="before-aside">
This is a kind of a blend between full export and incremental export.   

</span><aside class="sidenote">if someone can think of a better term for describing this concept, please let me know!</aside></div>
<p>
It's similar to full export in the sense that there isn't that much data to retrieve and if you could, you would just fetch it in one go.
</p>
<p>
However the difference that makes it similar to incremental exports is that you don't have all data available at once, only latest chunk.
The fundamental issue with synthetic exports is that no single export file will give you all of the data.
</p>
<p>
There are various reasons for that:
</p>
<ul class="org-ul">
<li><p>
API restrictions
</p>
<p>
Many APIs restrict number of items you can retrieve through each endpoint for caching and performance reasons.
</p>
<p>
Example: <a href="https://github.com/karlicoss/rexport#limitations">Reddit</a> limits your API queries to 1000 entries.
</p></li>
<li><p>
Limited memory
</p>
<p>
Example: autonomous devices like HR monitors or temperature monitors are embedded systems with limited memory.
</p>
<p>
Typically, they use some kind of <a href="https://en.wikipedia.org/wiki/Circular_buffer">ring buffer</a> so when you export data, you only get, say, latest 10000 measurements.
</p></li>
<li><p>
Disagreement on the 'state' of the system
</p>
<p>
Example: Kobo reader uses <a href="https://github.com/karlicoss/kobuddy">sqlite database</a> for keeping metadata like highlights, which is awesome!
However, when you delete the book from your reader, it removes your annotations and highlights from the database too.
</p>
<p>
There is absolutely no reason to do this: I delete the book because I don't need it on my reader, not because I want to get rid of annotations.
So in order to have all of them my only option is having regular database snapshots and assembling the full database from these pieces.
</p></li>
<li><p>
Security
</p>
<p>
Example: <a href="https://docs.monzo.com/#list-transactions">Monzo bank API</a>. 
</p>
<blockquote>
<p>
After a user has authenticated, your client can fetch all of their transactions, and after 5 minutes, it can only sync the last 90 days of transactions. If you need the user’s entire transaction history, you should consider fetching and storing it right after authentication. 
</p>
</blockquote>
<p>
So that means that unless you're happy with manually authorizing every time you export, you will only have access to the last 90 days of transactions.
</p>
<p>
Note: I feel kind of sorry complaining at Monzo, considering they are the nicest guys out there in terms of being dev friendly.
But that's the only example of such behavior I've seen so far.
</p></li>
</ul>
<p>
One important difference from other types of exports is that you <b>have to</b> do them regularly/often enough.
Otherwise, you inevitably miss some data and in best case, have to get it <a class="link-up" href="#export_manual">manually</a>, or in worst case, <a href="./takeout-data-gone.html">lose it forever</a>.
</p>
<p>
Now, you could deal with these same way you would with incremental exports, by pulling missing data only.
The <b>major difference</b> is that, if you do make a mistake in the logic, it's not just a matter of waiting to re-download everything. 
Some of the data might be gone <b>forever</b>.
</p>
<p>
So I take a hybrid approach instead: (TODO mention that I elaborate in DAL section)
</p>
<ul class="org-ul">
<li><p>
at <a class="link-down" href="#export_layer">export time</a>, retrieve all the data I can and keep it along with a timestamp, like <a class="link-up" href="#full">full export</a>.
</p>
<p>
Basically, it makes it 'append-only system', so there is no opportunity for losing data.
</p></li>
<li><p>
at <a class="link-down" href="#dal">data access time</a>, we dynamically build (synthesize) full state of the data
</p>
<p>
We go through through all chunks and reconstruct full state, similarly to <a class="link-up" href="#incremental">incremental export</a>.
That's where 'synthetic' comes from.
</p>
<p>
The full export only exists at runtime, and errors in merging logic are not problematic as you never overwrite data.
If you do spot a problem, you only have to change the code, no need for data migrations.
</p></li>
</ul>
</div>
<div class="outline-4" id="outline-container-org0000019">
<h4 id="org0000019">illustrative example</h4>
<div class="outline-text-4" id="text-org0000019">
<p>
I feel like the explanations are still slightly confusing, so let's consider a specific scenario.
</p>
<p>
Say you've got a temperature sensor that takes a measurement every minute and keeps it in its internal database.
It's only got enough memory for 2000 datapoints so you have to grab data from it every day, othewise older measurements would be overwritten.
</p>
<p>
It seems like a perfect fit for synthetic export. 
</p>
<ul class="org-ul">
<li><p>
export layer: every day you run a script that connects to the sensor and copies the database onto your computer
</p>
<p>
That's it, it doesn't do anything more complicated than that.
It's an idempotent operation, so if bluetooth connection fails, we can simply retry until we succeed without having to worry about transactional logic.
</p>
<p>
As a result we get a bunch of files like:
</p>
<pre class="example">
# ls /data/temperature/*.db
...
20190715100026.db
20190716100138.db
20190717101651.db
20190718100118.db
20190719100701.db
...
</pre></li>
<li><p>
data access layer: go through all chunks and construct the full temperature history
</p>
<p>
E.g. it would look kind of like:
</p>
<div class="org-src-container">
<pre class="src src-python"><span class="org-keyword">def</span> <span class="org-function-name">measurements</span>() -&gt; Iterator[<span class="org-builtin">float</span>]:
    processed: <span class="org-variable-name">Set</span>[datetime] = <span class="org-builtin">set</span>()
    <span class="org-keyword">for</span> db <span class="org-keyword">in</span> <span class="org-builtin">sorted</span>(Path(<span class="org-string">'/data/temperature'</span>).glob(<span class="org-string">'*.db'</span>)):
        <span class="org-keyword">for</span> timestamp, value <span class="org-keyword">in</span> query(db, <span class="org-string">'SELECT * FROM measurements'</span>):
            <span class="org-keyword">if</span> timestamp <span class="org-keyword">in</span> processed:
                <span class="org-keyword">continue</span>
            processed.add(timestamp)
            <span class="org-keyword">yield</span> value
</pre>
</div>
<p>
I hope it's clear how easier is this than having some sort of master sqlite database and updating it.
</p></li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-org000001a">
<h4 id="org000001a">summary</h4>
<div class="outline-text-4" id="text-org000001a">
<ul class="org-ul">
<li>advantages
<ul class="org-ul">
<li>much easier way to achieve incremental exports without having to worry about introducing inconsistencies</li>
<li><b>very resilient</b>, against pretty much everything: deleted content, data corruption, flaky APIs, programming errors</li>
<li><b>straightforward</b> to normalize and unify – you are not overwriting anything</li>
</ul></li>
<li>disadvantages
<ul class="org-ul">
<li><p>
takes <b>extra space</b>
</p>
<p>
That said, storage shouldn't be that much of a concern unless you export <b>very</b> often.
I elaborate more on this problem <a class="link-down" href="#disk_space">later in the post</a>.
</p></li>
<li><p>
<b>overhead</b> at access time
</p>
<p>
When we access the data we have to merge all snapshots every time.
</p>
<p>
Again, it only results in linear slowdown with time and pretty instantaneous for most data sources I have.
</p>
<p>
That can be addressed with TODO using iterators? (so access time is amortized)
</p></li>
</ul></li>
</ul>
</div>
</div>
<div class="outline-4" id="outline-container-org000001b">
<h4 id="org000001b">more examples</h4>
<div class="outline-text-4" id="text-org000001b">
<ul class="org-ul">
<li>github API is restricted to 300 latest events, so synthetic logic is used in <a href="https://github.com/karlicoss/ghexport/blob/master/model.py">ghexport</a> tool</li>
<li>reddit API is restricted to 1000 items, so synthetic logic is used in <a href="https://github.com/karlicoss/rexport/blob/874e6116bfba8cbd63fa3b4d93810a1488cb8464/dal.py#L136">rexport</a> tool</li>
<li><p>
chrome only keeps 90 days of browsing history in its database
</p>
<p>
You'd have to think about schema in advance. In addition, you'd have to manipulate data TODO
</p>
<p>
E.g. after reinstalling OS, database IDs (e.g. URLs and visits) will start from 0 again. If you simply merge the tables, it won't be consistent anymore.
</p>
<p>
However, if you treat is as a synthetic export, you have to:
</p>
<ul class="org-ul">
<li>simply copy the database file regularly (i.e. every week)</li>
<li>write code to go through all database fiels and accumulates the history</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org0000024">
<h2 id="export_layer"><a class="headerlink" href="#export_layer">¶</a><span class="section-number-2">4</span> Export layer</h2>
<div class="outline-text-2" id="text-export_layer">
<p>
No matter which of these ways  you have to use to export your data, there are some common difficulties, hence patterns which I'm going to explore in this section.
</p>
<p>
My guiding principle is: during the export, do the <b>absolute minimum</b> work required to reliably get raw data on your disk.
</p>
<p>
This is kind of vague (perhaps even obvious), so I will try to elavorate on what I mean by that.
</p>
<p>
This section doesn't cover the TODO exact specifics, but it's more of collection of tips of minimizing work necessary:
</p>
</div>
<div class="outline-3" id="outline-container-org000001f">
<h3 id="bindings"><a class="headerlink" href="#bindings">¶</a>use existing bindings</h3>
<div class="outline-text-3" id="text-bindings">
<p>
This may be obvious, but I still feel it has to be said.
Unless retrieving data is trivial (i.e. single GET request), chances that someone already invested effort in dealing with various API quirks.
Bindings often deal with dirty details like API limiting, retrying, pagination etc., so if you're lucky you might end up spending very little effort on actually exporting data.
</p>
<p>
If there is something in bindings you don't like or lack, it's still easier to <a href="https://en.wikipedia.org/wiki/Monkey_patch">monkey patch</a>, or just fork and patch them up (don't forget to open a pull request later!).
</p>
<p>
Also if you're the author of bindings, I have few requests. Please:
</p>
<ul class="org-ul">
<li>don't print in stdout, it's a pain to filter out and suppress. Ideally use proper logger modules</li>
</ul>
<ul class="org-ul">
<li>don't be overly defensive, or allow to <a href="mypy-error-handling.html#global_policy">configure</a> non-defensive behavior
It's quite sad when library silently catches all exception and replaces with empty strings/nulls/etc., without you knowing it.</li>
<li><p>
expose raw underlying data (e.g., json/xml from the API)
If you forget to handle something or the user disagrees how to interpret data they can hack it with accessing raw underlying TODO chunk??
</p>
<p>
Example of good data object:
</p>
<ul class="org-ul">
<li><a href="https://github.com/pawelad/pymonzo/blob/b5c8d4f46dcb3a2f475797a8b8ef1c15f6493fb9/src/pymonzo/api_objects.py#L38-L45">pymonzo</a> exposes programmer-friendly fields, but also keeps raw data</li>
</ul></li>
<li><p>
expose generic methods for handling API calls to make it easy to add new endpoints
</p>
<p>
Same argument: if you forget to handle some API calls, it makes it much easier for consumers to quickly add them.
</p></li>
</ul>
</div>
<div class="outline-4" id="outline-container-org000001e">
<h4 id="org000001e">examples</h4>
<div class="outline-text-4" id="text-org000001e">
<p>
To export <a href="https://github.com/karlicoss/hypexport">Hypothes.is</a> data I'm using existing <a href="https://github.com/judell/Hypothesis">judell/Hypothesis</a> bindings.
</p>
<ul class="org-ul">
<li>the bindings handle <a href="https://github.com/judell/Hypothesis/blob/91f881693546aaddc4096327a97f5cf342c3770a/hypothesis.py#L69">pagination and rate limits</a> for you</li>
<li>the bindings return raw jsons, making it trivial to serialize the data on disk</li>
</ul>
<ul class="org-ul">
<li><p>
the bindings expose generic <a href="https://github.com/judell/Hypothesis/blob/91f881693546aaddc4096327a97f5cf342c3770a/hypothesis.py#L138"><code class="inline">authenticated_api_query</code></a> method
</p>
<p>
For instance, profile data request was missing from the bindings; and it was <a href="https://github.com/karlicoss/hypexport/blob/7a80b36aa55da8b541e2778141eb84ada384d734/hypexport.py#L14">trivial</a> to get it anyway 
</p></li>
</ul>
<p>
Thanks to good bindings, the actual export is pretty much <a href="https://github.com/karlicoss/hypexport/blob/7a80b36aa55da8b541e2778141eb84ada384d734/hypexport.py#L6-L19">trivial</a>.
</p>
<p>
Another example: to export <a href="https://github.com/karlicoss/rexport/blob/master/rexport.py">Reddit data</a>, I'm using <a href="https://github.com/praw-dev/praw">praw</a>, excellent library for accessing Reddit from Python.
</p>
<ul class="org-ul">
<li>praw handles rate limits and pagination</li>
<li>praw exposes logger, which makes it easy to <a href="https://github.com/karlicoss/rexport/blob/874e6116bfba8cbd63fa3b4d93810a1488cb8464/export.py#L107">control it</a></li>
<li>praw supports all endpoints, so exporting data is just a matter of <a href="https://github.com/karlicoss/rexport/blob/d001e2d07d716130106ebe07a021f98d84a5ed93/rexport.py#L73-L84">calling right API methods</a></li>
<li><p>
one shortcoming of praw though is that it wouldn't give you access to raw JSON data for some reason, so we have to use some <a href="https://github.com/karlicoss/rexport/blob/d001e2d07d716130106ebe07a021f98d84a5ed93/rexport.py#L32-L55">hacky logic</a> to serialize.
</p>
<p>
If praw kept original data from the API, the <a href="https://github.com/karlicoss/rexport/blob/master/export.py">code for export</a> would be twice as short.
</p></li>
</ul>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org0000002">
<h3 id="org0000002"><a class="headerlink" href="#org0000002">¶</a>do not mess with raw data</h3>
<div class="outline-text-3" id="text-org0000002">
<p>
Keep the data you retrieved <b>as intact as possible</b>.
</p>
<p>
TODO link to DAL here?   
</p>
<p>
E.g. an api serves XML and you don't like working with it. Fair enough. But don't try to convert it to JSON prior to saving on disk.
</p>
<ul class="org-ul">
<li>if you do that, you will need to: deserialize XML (during export) -&gt; serialize to JSON (to save on disk) -&gt; deserialize JSON (to access data)</li>
<li>if you keep intact XML on disk, you'll just need to: deserialize XML (to access data)</li>
</ul>
<p>
Both approaches need working with XML at some point inevitably.
However the latter one is less error prone due to less chance of misinterpreting data and missing fields.
</p>
<p>
Instead, <b>keep the exporter code simple</b> and don't try to interpret data in it.
Move data interpretation burden to runtime and the <a class="link-down" href="#dal">data access layer</a> instead.
</p>
<p>
There are exceptions to this rule, e.g. when you need to use a database and have to impose a schema.
Even in that case it might be a good idea to be extra safe, keep data as raw json strings where feasible, and assert/warn on schema changes to be extra safe.
</p>
</div>
</div>
<div class="outline-3" id="outline-container-org0000003">
<h3 id="org0000003"><a class="headerlink" href="#org0000003">¶</a>do not be too defensive</h3>
<div class="outline-text-3" id="text-org0000003">
<p>
<b>Never</b> fallback on some wort of default values TODO
TODO generic requests module hook?? dunno.
TODO not sure how to communicate this point, I mean it's kinda of nice if one is willing to do this. But it's hard too
</p>
<p>
If you're willing to – go for it, but TODO it's hard
</p>
<p>
In my experience, it's fair to assume that if the export fails, it's a random server side glitch and not worth fine tuning, it's easier to start export all over again.
Hence, I don't deal with that in the individual export scripts at all, and instead use <a class="link-down" href="#arctee">arctee</a> to retry exports automatically.
</p>
<p>
I'd only recommend doing it if you know for sure that certain error 
</p>
</div>
</div>
<div class="outline-3" id="outline-container-org0000021">
<h3 id="output_stdout"><a class="headerlink" href="#output_stdout">¶</a>output to stdout</h3>
<div class="outline-text-3" id="text-output_stdout">
<p>
That's not always an option, e.g. if export is incremental and the underlying storage is sqlite.
However when feasible (e.g. json/csv), outputting to stdout makes your export composable with other tools and makes error handling easier:
</p>
<p>
TODO be atomic TODO applicable to incremental export
be familiar with the underlying storage you're using and its guarantees
</p>
<p>
TODO compression
TODO naming files
</p>
<p>
TODO elaborate more?
</p>
<p>
One particular example is atomic file writing.
Imagine you've started your export, opened a file and your program crashed in the middle of writing.
Typically that would mean a corrupted export file, that would cause issues downstream.
</p>
<p>
On many files systems moving files is atomic, which can be used to implement atomic writes. However it's somewhat <a href="https://stackoverflow.com/a/2333979/706389">boilerplaty</a>.
If you want to be portable (e.g. <a href="https://stackoverflow.com/a/167555/706389">support Windows</a>), it's going to be even harder to get right.
You really don't want to remember to copy paste it or reimplement every time.
</p>
</div>
<div class="outline-4" id="outline-container-org0000020">
<h4 id="org0000020"><span class="todo TODO">TODO</span> not sure how to integrate timestamps here? maybe separate export wrapper in a separate file?</h4>
</div>
</div>
<div class="outline-3" id="outline-container-org0000004">
<h3 id="org0000004"><a class="headerlink" href="#org0000004">¶</a><span class="timestamp-wrapper"><span class="timestamp">[2019-12-26 23:22]</span></span> allow reading credentials from a file</h3>
<div class="outline-text-3" id="text-org0000004">
<p>
TODO link to export<sub>helper</sub> here
</p>
<ul class="org-ul">
<li>you don't want them in your shell history or in crontabs</li>
<li><p>
Keeping them in file can potentially allow for finer control access
</p>
<p>
E.g. with Unix permissions you could only allow certain scripts to read secrets.
</p></li>
</ul>
<p>
Note that I'm not a security expert, so would be interested to know if there are better solutions to that
</p>
</div>
<div class="outline-4" id="outline-container-org0000022">
<h4 id="org0000022"><span class="todo TODO">TODO</span> <span class="timestamp-wrapper"><span class="timestamp">[2019-12-26 23:23]</span></span> even better, python script, e.g. potentially it makes it easier to put auth code close etc</h4>
<div class="outline-text-4" id="text-org0000022">
<p>
TODO also link to post that python is a good format for configs?
</p>
</div>
</div>
<div class="outline-4" id="outline-container-org0000023">
<h4 id="org0000023"><span class="todo TODO">TODO</span> <span class="priority">[C]</span> benefits of having secrets in python file: you can keep auth code close to the secrets   <span class="tag"><span class="blog">blog</span> <span class="python">python</span></span></h4>
<div class="outline-text-4" id="text-org0000023">
<p>
e.g. getting new secrets – rerun the secrets.py file
can leave comments (e.g. unlike json)
</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org0000005">
<h2 id="org0000005"><a class="headerlink" href="#org0000005">¶</a><span class="section-number-2">5</span> How to store it: organizing data</h2>
<div class="outline-text-2" id="text-5">
<p>
As I mentioned (TODO link), for the most parts I'm just keeping raw data from APIs.
For the storage I'm just using the filesystem; all exports are kept or symlinked in the same directory (<code class="inline">/exports</code>) for the ease of access:
</p>
<div class="org-src-container">
<pre class="src src-bash">find /exports/ | sort | head -n 20 | tail -n 7
</pre>
</div>
<pre class="example">
/exports/feedbin
/exports/feedly
/exports/firefox-history
/exports/fitbit
/exports/github
/exports/github-events
/exports/goodreads
</pre>
</div>
<div class="outline-3" id="outline-container-org0000025">
<h3 id="timestamps"><a class="headerlink" href="#timestamps">¶</a>naming and timestamping</h3>
<div class="outline-text-3" id="text-timestamps">
<p>
The only important bit is making sure that if you keep multiple exports (e.g. <a class="link-up" href="#synthetic">synthetic</a>), their names include timestamps, and time order is consistent with lexicographic order.
</p>
<p>
That means that that the only acceptable date/time format is some variation of <a href="https://en.wikipedia.org/wiki/ISO_8601"><code class="inline">YYYY MM DD HH MM SS Z</code></a>. 
Feel free to sprinkle it with any separators you like, or use milliseconds if you are really serious, but any other date format, e.g. <samp class="inline">MM/DD/YY</samp>, using month names, or not using zero-padded numbers is going to bring you serious grief.
</p>
<p>
E.g.:
</p>
<div class="org-src-container">
<pre class="src src-bash">ls /exports/instapaper/ | tail -n 5
</pre>
</div>
<pre class="example">
instapaper_20200101T000005Z.json
instapaper_20200101T040004Z.json
instapaper_20200101T080010Z.json
instapaper_20200101T120005Z.json
instapaper_20200101T160011Z.json
</pre>
<p>
Reason is it's automatically sort/max friendly, which massively reduces cognitive load when working with data.
</p>
<p>
To make timestamping automatic and less boilerplaty, I'm using a <a class="link-down" href="#arctee">wrapper script</a>.
</p>
</div>
</div>
<div class="outline-3" id="outline-container-org0000026">
<h3 id="backups"><a class="headerlink" href="#backups">¶</a>backups</h3>
<div class="outline-text-3" id="text-backups">
<p>
Backups are trivial: I can just run <a href="https://borgbackup.readthedocs.io/en/stable">borg</a> against <samp class="inline">/exports</samp>.
What is more, borg is deduplicating, so it's quite friendly to synthetic exports.
</p>
</div>
</div>
<div class="outline-3" id="outline-container-org0000027">
<h3 id="sync"><a class="headerlink" href="#sync">¶</a>synchronizing between computers</h3>
<div class="outline-text-3" id="text-sync">
<p>
I synchronize/replicate it across my computers with Syncthing, also used Dropbox in the past.
</p>
</div>
</div>
<div class="outline-3" id="outline-container-org0000029">
<h3 id="disk_space"><a class="headerlink" href="#disk_space">¶</a>disk space concerns</h3>
<div class="outline-text-3" id="text-disk_space">
<p>
TODO move stuff from synthetic exports here and interlink
TODO better heading?
</p>
<p>
With time, storage available grows exponentially and get cheaper, whereas amount of data you generate grows linearly, hence running exports periodically would only take 'quadratic' space.
</p>
<p>
If this is an issue, it can also be addressed with compression or even using deduplicating backup software like <a href="https://borgbackup.readthedocs.io/en/stable">borg</a> for storage. However, that would come at the cost of slowing down access.
</p>
<p>
As I mentioned, storage grows exponentially, whereas your exports grow linearly or quadratically depending on how to think about it.
</p>
<p>
For most of my exports, I don't even bother compressing, for the few that I do need to compress, TODO wrapper can handle it.
Remember that if you compress, you will typically be paying for it with ease and performance of data access.
</p>
<p>
There are potential ways of TODO
</p>
<ul class="org-ul">
<li><p>
keeping data under borg and using <a href="https://borgbackup.readthedocs.io/en/stable/usage/mount.html">borg mount</a> to access it.
</p>
<p>
You get deduplication for free, however this makes exporting and accessing data way more obscure, and in addition borg mount locks the repository so it's going to be read only while you access it.
</p></li>
<li><p>
using filesystem capable of compressing on the fly
</p>
<p>
E.g. <a href="https://serverfault.com/questions/740456/lightweight-transparent-compression-filesystem">ZFS/BTRFS</a>.
</p>
<p>
It seems straightforward enough, however be careful as it <a href="https://www.linuxuprising.com/2018/11/how-to-use-dropbox-on-non-ext4.html">might impact cloud sync</a>.
I haven't personally tried it.
</p></li>
</ul>
</div>
<div class="outline-4" id="outline-container-org0000028">
<h4 id="org0000028"><span class="todo STRT">STRT</span> <span class="timestamp-wrapper"><span class="timestamp">[2019-12-26 23:57]</span></span> compression – bwrapper</h4>
<div class="outline-text-4" id="text-org0000028">
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org000002a">
<h2 id="arctee"><a class="headerlink" href="#arctee">¶</a><span class="section-number-2">6</span> arctee</h2>
<div class="outline-text-2" id="text-arctee">
<p>
This is a <a href="https://github.com/karlicoss/arctee">wrapper script</a> I'm using to run most of my data exports.
</p>
<p>
Many things are very common to all data exports, regardless the source.
In vast majority of cases you want to fetch some data, save it in a json file long with a timestamp and potentially compress.
</p>
<p>
This script aims to minimize common boilerplate:
</p>
<ul class="org-ul">
<li><samp class="inline">path</samp> argument allows easy ISO8601 timestamping and guarantees atomic writing, so you'd never end up with corrupted exports.</li>
<li><samp class="inline">--compression</samp> allows to compress simply by passing format. No more <samp class="inline">tar -zcvf</samp>!</li>
<li><samp class="inline">--retries</samp> allows easy exponential backoff in case service you're querying is flaky.</li>
</ul>
<p>
Example:
</p>
<pre class="example">
arctee '/exports/rtm/{utcnow}.ical.xz' --compression xz --retries 3 -- /soft/export/rememberthemilk.py
</pre>
<ol class="org-ol">
<li><p>
runs <samp class="inline">/soft/export/rememberthemilk.py</samp>, retrying it up to three times if it fails
</p>
<p>
The script is expected to dump its result in stdout; stderr is simply passed through.
</p></li>
<li>once the data is fetched it's compressed as <samp class="inline">xz</samp></li>
<li>timestamp is computed and compressed data is written to <samp class="inline">/exports/rtm/20200102T170015Z.ical.xz</samp></li>
</ol>
<p>
Hopefully that explains some things I mentioned above:
</p>
<ul class="org-ul">
<li>dumping to stdout (TODO link): makes it easier to retry, be atomic and compress</li>
<li>not doing fine grained backoff (TODO link): I find that in almost all cases global backoff via <samp class="inline">--retries</samp> is sufficient TODO link</li>
</ul>
<p>
In addition, wrapper script is programming language agnostic, as long as you export script simply outputs to stdout, it doesn't matter how it's implemented.
</p>
<p>
That said, it feels kind of wrong to have an extra script for all these things since they are not hard in principle, just tedious and boring to do all over again. If anyone has bright ideas on simplifying parts of this, I'd be happy to know!
</p>
</div>
<div class="outline-3" id="outline-container-org0000006">
<h3 id="org0000006"><a class="headerlink" href="#org0000006">¶</a><span class="todo TODO">TODO</span> <span class="timestamp-wrapper"><span class="timestamp">[2019-12-28 23:56]</span></span> I guess in 'DAL' mention that bwrapper is useful here too.</h3>
</div>
<div class="outline-3" id="outline-container-org0000007">
<h3 id="org0000007"><a class="headerlink" href="#org0000007">¶</a><span class="todo TODO">TODO</span> <span class="timestamp-wrapper"><span class="timestamp">[2020-01-19 18:34]</span></span> dunno, perhaps move to 'appendix'?? along with cachew?</h3>
</div>
</div>
<div class="outline-2" id="outline-container-org000002b">
<h2 id="automatic_exports"><a class="headerlink" href="#automatic_exports">¶</a><span class="section-number-2">7</span> Automating exports</h2>
<div class="outline-text-2" id="text-automatic_exports">
<p>
TODO motivate automation  
TODO having recent version of your data motivates you to actually use it, otherwise your tool ceases to be usefule
TODO backup
</p>
<p>
I run most of my data exports at least daily, so it needs to be automated.
I highly recommend doing the same, otherwise it's really annoying having your data stale and remembering to run export manually.
</p>
<p>
At the moment, I'm using cron (to be more specific, <a href="scheduler.html#fcron">fcron</a>).
I'm still <a href="scheduler.html#solution">considering</a> an alternative, but overall using cron is okay.
I wish there existed a user-friendlier tool for running periodic tasks, <span style="color:darkorange"><strong>so if you know one, please let me know!</strong></span>
</p>
</div>
</div>
<div class="outline-2" id="outline-container-org000002c">
<h2 id="dal"><a class="headerlink" href="#dal">¶</a><span class="section-number-2">8</span> Data access layer (DAL)</h2>
<div class="outline-text-2" id="text-dal">
<p>
  As I mentioned in the <a class="link-up" href="#design">design principles</a>, I'm trying to keep data retrieval code and data access code separate,
because they serve very different purposes and deal with very different errors.
</p>
</div>
<div class="outline-3" id="outline-container-org0000008">
<h3 id="org0000008"><a class="headerlink" href="#org0000008">¶</a>you need to cache data on the disk anywa</h3>
<div class="outline-text-3" id="text-org0000008">
<p>
I'll try to go though the points arguing that this is a reasonable way to organize the code.
TODO link to 
</p>
<ul class="org-ul">
<li>you probably want it as a means of backup. TODO link?</li>
<li>keeping raw data as an intermediate allows to use different programming languages and tools to export and access data</li>
<li>main argumnet: when you actually use your data in your tools, you don't want to retrieve it from the API every time: it's flaky and you might TODO rate limits.
TODO demotivates</li>
</ul>
</div>
</div>
<div class="outline-3" id="outline-container-org0000009">
<h3 id="org0000009"><a class="headerlink" href="#org0000009">¶</a><span class="todo TODO">TODO</span> <span class="priority">[C]</span> would be nice to have main for models?   <span class="tag"><span class="dataliberation">dataliberation</span></span></h3>
<div class="outline-text-3" id="text-org0000009">
</div>
</div>
<div class="outline-3" id="outline-container-org000000a">
<h3 id="org000000a"><a class="headerlink" href="#org000000a">¶</a><span class="todo TODO">TODO</span> it's also an experiment in organizing code. demo etc, immediately visualize stuff with pandas   <span class="tag"><span class="exports">exports</span> <span class="blog">blog</span> <span class="dal">dal</span></span></h3>
<div class="outline-text-3" id="text-org000000a">
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org000000b">
<h2 id="org000000b"><a class="headerlink" href="#org000000b">¶</a><span class="section-number-2">9</span> --</h2>
<div class="outline-text-2" id="text-9">
<p>
TODO Approaches I describe works well for me so far. It feels like it's fairly composable, allows for injection TODO and TODO
</p>
<p>
However, it still feels like something that shouldn't have been so hard in the first place and ??? to be solved in a more generic way.
</p>
</div>
</div>
<div class="outline-2" id="outline-container-org000000c">
<h2 id="org000000c"><a class="headerlink" href="#org000000c">¶</a><span class="section-number-2">10</span> <span class="todo TODO">TODO</span> add rationale behind the dal/export separation   <span class="tag"><span class="exports">exports</span></span></h2>
<div class="outline-text-2" id="text-10">
</div>
</div>

    </section>

    
    <section class="footer">
        <div class="post-tags"><a class="post-tag" href="./tags.html#infra">#infra</a> <a class="post-tag" href="./tags.html#dataliberation">#dataliberation</a> <a class="post-tag" href="./tags.html#pkm">#pkm</a></div>
        <!-- TODO post-date? -->
        <div class="date">01 January 2020</div>
    </section>
    

    

    <section class="comments">
    <script data-isso="https://beepb00p.xyz/comments/" data-isso-reply-to-self="true" src="https://beepb00p.xyz/comments/js/embed.min.js">
</script>

<section id="isso-thread" data-isso-id="isso_exports"></section>

    </section>

</article>

        </main>

        <!-- TODO hmm maybe display something in a footer, so it's clear it's end of content... -->
        

        <!-- TODO make semantic -->
        <footer>
            <span style="float:left">
            <a href="https://twitter.com/karlicoss">🐦 me @twitter</a>
            ·
            <a href="https://github.com/karlicoss">💻 me @github</a>
            </span>

            <a href="http://creativecommons.org/licenses/by/4.0">CC BY 4.0</a>
            
            
        </footer>
    </body>
</html>
